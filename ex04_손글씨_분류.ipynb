{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPd9l6a7eJ5X0pF809O69Lh",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/didlaak/python/blob/main/ex04_%EC%86%90%EA%B8%80%EC%94%A8_%EB%B6%84%EB%A5%98.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8hufrAD234HW"
      },
      "outputs": [],
      "source": [
        "# 손글씨 데이터를 가져와서 분석해보기\n",
        "# 0 ~ 9 까지의 숫자"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.datasets import mnist\n",
        "((X_train,y_train),(X_test,y_test)) = mnist.load_data()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1w1RDIUu366M",
        "outputId": "e17740c0-ad65-404d-8af3-0b58e9c4f88d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11490434/11490434 [==============================] - 0s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 데이터 갯수, 세로크기, 가로크기\n",
        "X_train.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-AXApGEy368r",
        "outputId": "45aa122b-ab89-4e1a-eb2d-7c4085447f71"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(60000, 28, 28)"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 0 > 검은색\n",
        "# 255 > 흰색\n",
        "# 28 * 28 픽셀로 이루어져있음\n",
        "X_train[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wa0Ni-Bi36_D",
        "outputId": "98f93856-d94d-416b-fca7-f1491f06bf5d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   3,\n",
              "         18,  18,  18, 126, 136, 175,  26, 166, 255, 247, 127,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,  30,  36,  94, 154, 170,\n",
              "        253, 253, 253, 253, 253, 225, 172, 253, 242, 195,  64,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,  49, 238, 253, 253, 253, 253,\n",
              "        253, 253, 253, 253, 251,  93,  82,  82,  56,  39,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,  18, 219, 253, 253, 253, 253,\n",
              "        253, 198, 182, 247, 241,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,  80, 156, 107, 253, 253,\n",
              "        205,  11,   0,  43, 154,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,  14,   1, 154, 253,\n",
              "         90,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 139, 253,\n",
              "        190,   2,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  11, 190,\n",
              "        253,  70,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  35,\n",
              "        241, 225, 160, 108,   1,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         81, 240, 253, 253, 119,  25,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,  45, 186, 253, 253, 150,  27,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,  16,  93, 252, 253, 187,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0, 249, 253, 249,  64,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,  46, 130, 183, 253, 253, 207,   2,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  39,\n",
              "        148, 229, 253, 253, 253, 250, 182,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  24, 114, 221,\n",
              "        253, 253, 253, 253, 201,  78,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,  23,  66, 213, 253, 253,\n",
              "        253, 253, 198,  81,   2,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,  18, 171, 219, 253, 253, 253, 253,\n",
              "        195,  80,   9,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,  55, 172, 226, 253, 253, 253, 253, 244, 133,\n",
              "         11,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0, 136, 253, 253, 253, 212, 135, 132,  16,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0]], dtype=uint8)"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 데이터 확인\n",
        "import matplotlib.pyplot as plt\n",
        "plt.imshow(X_train[0], cmap ='gray')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "prZKn12r37Bb",
        "outputId": "12ac0016-ca79-4f51-f6f5-74b92b672739"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 이미지에서 해주면 좋은 전처리\n",
        "# 조금더 효율적인 방법\n",
        "# 값이 0 ~ 255(정수)로 분포\n",
        "# 분산이 크기때문에 계산상에 오류가 발생할 수 있음\n",
        "# 적은 범위의 숫자로 표현 > 0 ~ 1(실수)\n",
        "\n",
        "X_train = X_train.astype('float') / 255\n",
        "X_test = X_test.astype('float') / 255\n"
      ],
      "metadata": {
        "id": "u_cqYW5f37D7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dense의 한계\n",
        "# 1차원만 학습 가능 -> 데이터가 모양을 잃어 모양이 가지는 의미가 사라짐\n",
        "X_train = X_train.reshape((60000, 28*28))\n",
        "X_test = X_test.reshape((10000, 28*28))\n",
        "\n"
      ],
      "metadata": {
        "id": "UsSfCnic37GN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aKIPY23J-tgs",
        "outputId": "a3c05237-ffc4-4ff4-c970-68fa02b9bc90"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(60000, 784)"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 다중분류\n",
        "# 다중분류시에는 y데이터에 원핫 인코딩\n",
        "import pandas as pd\n",
        "y_train = pd.get_dummies(y_train)\n",
        "y_test = pd.get_dummies(y_test)"
      ],
      "metadata": {
        "id": "j6qrlovB37I-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras import Sequential # 딥러닝 모델의 뼈대\n",
        "from tensorflow.keras.layers import InputLayer, Dense\n",
        "\n",
        "model1 = Sequential()\n",
        "# 모델 설계\n",
        "# relu가 대체로 잘 나오지만 비교하기 위해서 sigmoid를 사용해보자\n",
        "\n",
        "model1.add(Dense(units = 512, activation = 'sigmoid', input_dim=784)) \n",
        "\n",
        "# 학습방법 설정\n",
        "model1.add(Dense(units = 34, activation = 'sigmoid')) \n",
        "model1.add(Dense(units = 54, activation = 'sigmoid')) \n",
        "model1.add(Dense(units = 26, activation = 'sigmoid')) \n",
        "\n",
        "model1.add(Dense(units = 10, activation = 'softmax')) \n",
        "\n",
        "model1.compile(loss ='categorical_crossentropy', \n",
        "               optimizer ='SGD', \n",
        "               metrics=['accuracy'])\n",
        "#model1.fit(X_train,y_train, epochs = 20, validation_data = (X_test,y_test))"
      ],
      "metadata": {
        "id": "ch4_v3Xb37OB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model1.fit(X_train,y_train, epochs = 20, validation_data = (X_test,y_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uEfiMHma37Sv",
        "outputId": "73a1df4a-fa06-4bf7-ee6c-96948acb99c5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 2.3054 - accuracy: 0.1116 - val_loss: 2.3004 - val_accuracy: 0.1135\n",
            "Epoch 2/20\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 2.3007 - accuracy: 0.1128 - val_loss: 2.3000 - val_accuracy: 0.1028\n",
            "Epoch 3/20\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: 2.2999 - accuracy: 0.1132 - val_loss: 2.2990 - val_accuracy: 0.1135\n",
            "Epoch 4/20\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 2.2990 - accuracy: 0.1142 - val_loss: 2.2981 - val_accuracy: 0.1135\n",
            "Epoch 5/20\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 2.2977 - accuracy: 0.1143 - val_loss: 2.2961 - val_accuracy: 0.1135\n",
            "Epoch 6/20\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 2.2958 - accuracy: 0.1191 - val_loss: 2.2944 - val_accuracy: 0.1135\n",
            "Epoch 7/20\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 2.2931 - accuracy: 0.1213 - val_loss: 2.2909 - val_accuracy: 0.1158\n",
            "Epoch 8/20\n",
            "1875/1875 [==============================] - 11s 6ms/step - loss: 2.2888 - accuracy: 0.1418 - val_loss: 2.2853 - val_accuracy: 0.1442\n",
            "Epoch 9/20\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 2.2811 - accuracy: 0.1493 - val_loss: 2.2738 - val_accuracy: 0.1205\n",
            "Epoch 10/20\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 2.2640 - accuracy: 0.1847 - val_loss: 2.2467 - val_accuracy: 0.2243\n",
            "Epoch 11/20\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 2.2103 - accuracy: 0.2550 - val_loss: 2.1462 - val_accuracy: 0.2847\n",
            "Epoch 12/20\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 2.0270 - accuracy: 0.3166 - val_loss: 1.8905 - val_accuracy: 0.3252\n",
            "Epoch 13/20\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 1.8043 - accuracy: 0.3603 - val_loss: 1.7197 - val_accuracy: 0.4045\n",
            "Epoch 14/20\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 1.6410 - accuracy: 0.4216 - val_loss: 1.5510 - val_accuracy: 0.4478\n",
            "Epoch 15/20\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 1.4831 - accuracy: 0.4619 - val_loss: 1.4146 - val_accuracy: 0.4843\n",
            "Epoch 16/20\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 1.3717 - accuracy: 0.4909 - val_loss: 1.3181 - val_accuracy: 0.5138\n",
            "Epoch 17/20\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 1.2814 - accuracy: 0.5298 - val_loss: 1.2292 - val_accuracy: 0.5519\n",
            "Epoch 18/20\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 1.1913 - accuracy: 0.5798 - val_loss: 1.1349 - val_accuracy: 0.6149\n",
            "Epoch 19/20\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 1.0954 - accuracy: 0.6312 - val_loss: 1.0369 - val_accuracy: 0.6699\n",
            "Epoch 20/20\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.9933 - accuracy: 0.6792 - val_loss: 0.9321 - val_accuracy: 0.6994\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f6fc40f9040>"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "activation : sigmoid - 학습을 못함\n",
        "\n",
        "optimizer : SGD - 학습을 느리게, 다르게 함"
      ],
      "metadata": {
        "id": "Htl9WxVDziIp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras import Sequential # 딥러닝 모델의 뼈대\n",
        "from tensorflow.keras.layers import InputLayer, Dense\n",
        "\n",
        "model2 = Sequential()\n",
        "# 모델 설계\n",
        "# relu가 대체로 잘 나오지만 비교하기 위해서 sigmoid를 사용해보자\n",
        "\n",
        "model2.add(Dense(units = 512, activation = 'relu', input_dim=784)) \n",
        "\n",
        "# 학습방법 설정\n",
        "model2.add(Dense(units = 34, activation = 'relu')) \n",
        "model2.add(Dense(units = 54, activation = 'relu')) \n",
        "model2.add(Dense(units = 26, activation = 'relu')) \n",
        "\n",
        "model2.add(Dense(units = 10, activation = 'softmax')) \n",
        "\n",
        "model2.compile(loss ='categorical_crossentropy', \n",
        "               optimizer ='SGD', \n",
        "               metrics=['accuracy'])\n",
        "model2.fit(X_train,y_train, epochs = 20, validation_data = (X_test,y_test))"
      ],
      "metadata": {
        "id": "LtWRMS0X37Vk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "33fb19a1-ff84-4a3d-c2c5-119443e7c75d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.7158 - accuracy: 0.7803 - val_loss: 0.2926 - val_accuracy: 0.9157\n",
            "Epoch 2/20\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.2418 - accuracy: 0.9293 - val_loss: 0.2069 - val_accuracy: 0.9406\n",
            "Epoch 3/20\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.1775 - accuracy: 0.9484 - val_loss: 0.1546 - val_accuracy: 0.9529\n",
            "Epoch 4/20\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.1392 - accuracy: 0.9603 - val_loss: 0.1284 - val_accuracy: 0.9613\n",
            "Epoch 5/20\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.1130 - accuracy: 0.9677 - val_loss: 0.1252 - val_accuracy: 0.9623\n",
            "Epoch 6/20\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0935 - accuracy: 0.9725 - val_loss: 0.1061 - val_accuracy: 0.9680\n",
            "Epoch 7/20\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0796 - accuracy: 0.9762 - val_loss: 0.0999 - val_accuracy: 0.9695\n",
            "Epoch 8/20\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0673 - accuracy: 0.9806 - val_loss: 0.0916 - val_accuracy: 0.9705\n",
            "Epoch 9/20\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0570 - accuracy: 0.9836 - val_loss: 0.0901 - val_accuracy: 0.9731\n",
            "Epoch 10/20\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0490 - accuracy: 0.9861 - val_loss: 0.0836 - val_accuracy: 0.9746\n",
            "Epoch 11/20\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0419 - accuracy: 0.9879 - val_loss: 0.0925 - val_accuracy: 0.9726\n",
            "Epoch 12/20\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0357 - accuracy: 0.9902 - val_loss: 0.0786 - val_accuracy: 0.9780\n",
            "Epoch 13/20\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0303 - accuracy: 0.9922 - val_loss: 0.0763 - val_accuracy: 0.9779\n",
            "Epoch 14/20\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0258 - accuracy: 0.9930 - val_loss: 0.0781 - val_accuracy: 0.9774\n",
            "Epoch 15/20\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0220 - accuracy: 0.9947 - val_loss: 0.0769 - val_accuracy: 0.9784\n",
            "Epoch 16/20\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0187 - accuracy: 0.9956 - val_loss: 0.0800 - val_accuracy: 0.9785\n",
            "Epoch 17/20\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0152 - accuracy: 0.9968 - val_loss: 0.0775 - val_accuracy: 0.9784\n",
            "Epoch 18/20\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0131 - accuracy: 0.9973 - val_loss: 0.0860 - val_accuracy: 0.9751\n",
            "Epoch 19/20\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0107 - accuracy: 0.9980 - val_loss: 0.0812 - val_accuracy: 0.9784\n",
            "Epoch 20/20\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0088 - accuracy: 0.9985 - val_loss: 0.0830 - val_accuracy: 0.9774\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f6fc4150cd0>"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras import Sequential # 딥러닝 모델의 뼈대\n",
        "from tensorflow.keras.layers import InputLayer, Dense\n",
        "\n",
        "model3 = Sequential()\n",
        "# 모델 설계\n",
        "# relu가 대체로 잘 나오지만 비교하기 위해서 sigmoid를 사용해보자\n",
        "\n",
        "model3.add(Dense(units = 512, activation = 'sigmoid', input_dim=784)) \n",
        "\n",
        "# 학습방법 설정\n",
        "model3.add(Dense(units = 34, activation = 'sigmoid')) \n",
        "model3.add(Dense(units = 54, activation = 'sigmoid')) \n",
        "model3.add(Dense(units = 26, activation = 'sigmoid')) \n",
        "\n",
        "model3.add(Dense(units = 10, activation = 'softmax')) \n",
        "\n",
        "model3.compile(loss ='categorical_crossentropy', \n",
        "               optimizer ='Adam', \n",
        "               metrics=['accuracy'])\n",
        "model3.fit(X_train,y_train, epochs = 20, validation_data = (X_test,y_test))"
      ],
      "metadata": {
        "id": "xNQNO4VZ37YL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "834abd74-b518-4980-c58a-4dbcb2b54240"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "1875/1875 [==============================] - 9s 4ms/step - loss: 0.8310 - accuracy: 0.7758 - val_loss: 0.2763 - val_accuracy: 0.9337\n",
            "Epoch 2/20\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.1920 - accuracy: 0.9527 - val_loss: 0.1532 - val_accuracy: 0.9599\n",
            "Epoch 3/20\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.1199 - accuracy: 0.9688 - val_loss: 0.1301 - val_accuracy: 0.9662\n",
            "Epoch 4/20\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0870 - accuracy: 0.9764 - val_loss: 0.1166 - val_accuracy: 0.9675\n",
            "Epoch 5/20\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0669 - accuracy: 0.9822 - val_loss: 0.0964 - val_accuracy: 0.9739\n",
            "Epoch 6/20\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0514 - accuracy: 0.9858 - val_loss: 0.0866 - val_accuracy: 0.9759\n",
            "Epoch 7/20\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0399 - accuracy: 0.9886 - val_loss: 0.0916 - val_accuracy: 0.9752\n",
            "Epoch 8/20\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0327 - accuracy: 0.9904 - val_loss: 0.1050 - val_accuracy: 0.9728\n",
            "Epoch 9/20\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0266 - accuracy: 0.9924 - val_loss: 0.0971 - val_accuracy: 0.9741\n",
            "Epoch 10/20\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0212 - accuracy: 0.9938 - val_loss: 0.0921 - val_accuracy: 0.9767\n",
            "Epoch 11/20\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0184 - accuracy: 0.9946 - val_loss: 0.1075 - val_accuracy: 0.9746\n",
            "Epoch 12/20\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0160 - accuracy: 0.9953 - val_loss: 0.0935 - val_accuracy: 0.9782\n",
            "Epoch 13/20\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0122 - accuracy: 0.9966 - val_loss: 0.0978 - val_accuracy: 0.9761\n",
            "Epoch 14/20\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0114 - accuracy: 0.9968 - val_loss: 0.1005 - val_accuracy: 0.9773\n",
            "Epoch 15/20\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0118 - accuracy: 0.9966 - val_loss: 0.1056 - val_accuracy: 0.9759\n",
            "Epoch 16/20\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0101 - accuracy: 0.9969 - val_loss: 0.0951 - val_accuracy: 0.9791\n",
            "Epoch 17/20\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0083 - accuracy: 0.9975 - val_loss: 0.1012 - val_accuracy: 0.9782\n",
            "Epoch 18/20\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0093 - accuracy: 0.9972 - val_loss: 0.1098 - val_accuracy: 0.9764\n",
            "Epoch 19/20\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0062 - accuracy: 0.9983 - val_loss: 0.0986 - val_accuracy: 0.9796\n",
            "Epoch 20/20\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0081 - accuracy: 0.9975 - val_loss: 0.0999 - val_accuracy: 0.9784\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f6fa6e352e0>"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras import Sequential # 딥러닝 모델의 뼈대\n",
        "from tensorflow.keras.layers import InputLayer, Dense\n",
        "\n",
        "model4 = Sequential()\n",
        "# 모델 설계\n",
        "# relu가 대체로 잘 나오지만 비교하기 위해서 sigmoid를 사용해보자\n",
        "\n",
        "model4.add(Dense(units = 512, activation = 'relu', input_dim=784)) \n",
        "\n",
        "# 학습방법 설정\n",
        "model4.add(Dense(units = 34, activation = 'relu')) \n",
        "model4.add(Dense(units = 54, activation = 'relu')) \n",
        "model4.add(Dense(units = 26, activation = 'relu')) \n",
        "\n",
        "model4.add(Dense(units = 10, activation = 'softmax')) \n",
        "\n",
        "model4.compile(loss ='categorical_crossentropy', \n",
        "               optimizer ='Adam', \n",
        "               metrics=['accuracy'])\n",
        "model4.fit(X_train,y_train, epochs = 20, validation_data = (X_test,y_test))"
      ],
      "metadata": {
        "id": "_fnTH22y37ai",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ebb93f87-f066-42b8-ba21-ec077cd09d85"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "1875/1875 [==============================] - 9s 4ms/step - loss: 0.2456 - accuracy: 0.9269 - val_loss: 0.1379 - val_accuracy: 0.9586\n",
            "Epoch 2/20\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0983 - accuracy: 0.9702 - val_loss: 0.0889 - val_accuracy: 0.9740\n",
            "Epoch 3/20\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0685 - accuracy: 0.9792 - val_loss: 0.0915 - val_accuracy: 0.9734\n",
            "Epoch 4/20\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0530 - accuracy: 0.9832 - val_loss: 0.0750 - val_accuracy: 0.9793\n",
            "Epoch 5/20\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0412 - accuracy: 0.9874 - val_loss: 0.0796 - val_accuracy: 0.9784\n",
            "Epoch 6/20\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0355 - accuracy: 0.9888 - val_loss: 0.1000 - val_accuracy: 0.9722\n",
            "Epoch 7/20\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0303 - accuracy: 0.9902 - val_loss: 0.0798 - val_accuracy: 0.9801\n",
            "Epoch 8/20\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0247 - accuracy: 0.9920 - val_loss: 0.0986 - val_accuracy: 0.9777\n",
            "Epoch 9/20\n",
            "1875/1875 [==============================] - 7s 3ms/step - loss: 0.0204 - accuracy: 0.9933 - val_loss: 0.0926 - val_accuracy: 0.9783\n",
            "Epoch 10/20\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0209 - accuracy: 0.9932 - val_loss: 0.0847 - val_accuracy: 0.9811\n",
            "Epoch 11/20\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0198 - accuracy: 0.9944 - val_loss: 0.0976 - val_accuracy: 0.9795\n",
            "Epoch 12/20\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0171 - accuracy: 0.9946 - val_loss: 0.0942 - val_accuracy: 0.9775\n",
            "Epoch 13/20\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0167 - accuracy: 0.9949 - val_loss: 0.1010 - val_accuracy: 0.9780\n",
            "Epoch 14/20\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0145 - accuracy: 0.9955 - val_loss: 0.0952 - val_accuracy: 0.9804\n",
            "Epoch 15/20\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0132 - accuracy: 0.9959 - val_loss: 0.0971 - val_accuracy: 0.9792\n",
            "Epoch 16/20\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0141 - accuracy: 0.9960 - val_loss: 0.0866 - val_accuracy: 0.9816\n",
            "Epoch 17/20\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0131 - accuracy: 0.9961 - val_loss: 0.0896 - val_accuracy: 0.9818\n",
            "Epoch 18/20\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0104 - accuracy: 0.9967 - val_loss: 0.1018 - val_accuracy: 0.9801\n",
            "Epoch 19/20\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0106 - accuracy: 0.9970 - val_loss: 0.1148 - val_accuracy: 0.9780\n",
            "Epoch 20/20\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0109 - accuracy: 0.9968 - val_loss: 0.0942 - val_accuracy: 0.9837\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f6fb6e53610>"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 직접 적은 손글씨 인식시키기\n"
      ],
      "metadata": {
        "id": "FZdlMAKY4gHX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import PIL.Image as pimg\n",
        "img = pimg.open('/content/num4.gif')"
      ],
      "metadata": {
        "id": "8xkkxSH44gJ2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.imshow(img)\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "98aCYtBd4gMH",
        "outputId": "51ff6dc4-9324-47f8-91de-a37d0618653a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD4CAYAAAAq5pAIAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/NK7nSAAAACXBIWXMAAAsTAAALEwEAmpwYAAALrUlEQVR4nO3dT6hc5R3G8eepfzbqImmGEGJorLjRQqM5hIIiFqnEbKILg1lICsLNQkHBRcUuct2FUpUuiuRag2mxSkTFLEKrDYK4EedKav7RxkrEhGsyIQvjykZ/XdwTuUnu/MmcM3Om+X0/MMyZ952Z8+Nwn3tmzjvnvI4IAbjy/ajpAgCMB2EHkiDsQBKEHUiCsANJXD3OlS1btixWr149zlUCqRw7dkynT5/2Yn2Vwm57vaQ/SLpK0p8iYnuv569evVrtdrvKKgH0UBRF176hP8bbvkrSHyXdL+lWSZtt3zrs+wEYrSrf2ddJ+iwiPo+IbyW9LmljPWUBqFuVsK+U9OWCx8fLtgvYnrLdtt3udDoVVgegipEfjY+ImYgoIqJotVqjXh2ALqqE/YSkVQse31i2AZhAVcL+saRbbN9k+1pJD0vaU09ZAOo29NBbRJyz/bikv2t+6G1nRByqrTIAtao0zh4ReyXtrakWACPEz2WBJAg7kARhB5Ig7EAShB1IgrADSYz1fHZceWbemOnd/2z3/qltUz1fO/VQ735cHvbsQBKEHUiCsANJEHYgCcIOJEHYgSQYekNP/YbWtm7aOvR793vtVDD0Vif27EAShB1IgrADSRB2IAnCDiRB2IEkCDuQBOPsyY1yHL2ftbetHdl741Ls2YEkCDuQBGEHkiDsQBKEHUiCsANJEHYgCcbZrwCzb8x27SueLXq/uMFJtmcPda8b9asUdtvHJJ2V9J2kcxHR5y8LQFPq2LP/MiJO1/A+AEaI7+xAElXDHpLetT1re9ELhtmest223e50OhVXB2BYVcN+V0TcIel+SY/ZvvviJ0TETEQUEVG0Wq2KqwMwrEphj4gT5f0pSW9LWldHUQDqN3TYbV9n+4bzy5Luk3SwrsIA1KvK0fjlkt62ff59/hoRf6ulKlyg1zi6JBWbGPFEf0OHPSI+l/TzGmsBMEIMvQFJEHYgCcIOJEHYgSQIO5AEp7hOgCYv59zP1EO9p03uVzsmB3t2IAnCDiRB2IEkCDuQBGEHkiDsQBKEHUiCcfYazBzuPdY8c1vv/lk1d0nlfuPoO3bv6Nk/Y8bZ/1+wZweSIOxAEoQdSIKwA0kQdiAJwg4kQdiBJBhnH1Cvyzk3eb55P1PTfcbRt/UeR8eVgz07kARhB5Ig7EAShB1IgrADSRB2IAnCDiTBOHtp9vDkTotc9ZxzQBpgz257p+1Ttg8uaFtq+z3bR8v7JaMtE0BVg3yMf0XS+ovanpa0LyJukbSvfAxggvUNe0R8IOnMRc0bJe0ql3dJeqDesgDUbdgDdMsjYq5c/krS8m5PtD1lu2273el0hlwdgKoqH42PiJAUPfpnIqKIiKLValVdHYAhDRv2k7ZXSFJ5f6q+kgCMwrBh3yNpS7m8RdI79ZQDYFT6jrPbfk3SPZKW2T4uaZuk7ZJ2235U0heSNo2yyHEobmtwHJ1zzjEGfcMeEZu7dN1bcy0ARoifywJJEHYgCcIOJEHYgSQIO5BEmlNcZ96Y3KmFZ6b7TPncp/9KZbvpErpaq7U9+6d29x5O7Xfa8iiwZweSIOxAEoQdSIKwA0kQdiAJwg4kQdiBJDx/oZnxKIoi2u322NZ3wbrd+xTWWfW+lDRQp1HlrigKtdvtRX+gwJ4dSIKwA0kQdiAJwg4kQdiBJAg7kARhB5JIcz772une5x/PTjPOjvo0cb56P+zZgSQIO5AEYQeSIOxAEoQdSIKwA0kQdiCJNOezYzRGeW33cf5tXikqnc9ue6ftU7YPLmibtn3C9v7ytqHOggHUb5CP8a9IWr9I+wsRsaa87a23LAB16xv2iPhA0pkx1AJghKocoHvc9qflx/wl3Z5ke8p223a70+lUWB2AKoYN+4uSbpa0RtKcpOe6PTEiZiKiiIii1WoNuToAVQ0V9og4GRHfRcT3kl6StK7esgDUbaiw216x4OGDkg52ey6AydD3fHbbr0m6R9Iy28clbZN0j+01kkLSMUlbR1cigDr0DXtEbF6k+eUR1AJghPi5LJAEYQeSIOxAEoQdSIKwA0kQdiAJwg4kQdiBJAg7kARhB5Ig7EAShB1IgrADSRB2IAnCDiRB2IEkCDuQBGEHkiDsQBKEHUiCsANJEHYgCcIOJEHYgSQIO5AEYQeSIOxAEoQdSIKwA0kQdiCJvmG3vcr2+7YP2z5k+4myfant92wfLe+XjL5cAMMaZM9+TtJTEXGrpF9Iesz2rZKelrQvIm6RtK98DGBC9Q17RMxFxCfl8llJRyStlLRR0q7yabskPTCiGgHU4LK+s9teLel2SR9JWh4Rc2XXV5KWd3nNlO227Xan06lSK4AKBg677eslvSnpyYj4emFfRISkWOx1ETETEUVEFK1Wq1KxAIY3UNhtX6P5oL8aEW+VzSdtryj7V0g6NZoSAdRhkKPxlvSypCMR8fyCrj2StpTLWyS9U395AOpy9QDPuVPSI5IO2N5ftj0jabuk3bYflfSFpE0jqRBALfqGPSI+lOQu3ffWWw6AUeEXdEAShB1IgrADSRB2IAnCDiQxyNAb0NWO6R09+7dOb+3aN/XQVN3loAf27EAShB1IgrADSRB2IAnCDiRB2IEkCDuQhOcvMjMeRVFEu90e2/qAbIqiULvdXvQsVfbsQBKEHUiCsANJEHYgCcIOJEHYgSQIO5AEYQeSIOxAEoQdSIKwA0kQdiAJwg4kQdiBJAg7kMQg87Ovsv2+7cO2D9l+omyftn3C9v7ytmH05QIY1iCTRJyT9FREfGL7Bkmztt8r+16IiN+PrjwAdRlkfvY5SXPl8lnbRyStHHVhAOp1Wd/Zba+WdLukj8qmx21/anun7SVdXjNlu2273el0qlULYGgDh9329ZLelPRkRHwt6UVJN0tao/k9/3OLvS4iZiKiiIii1WpVrxjAUAYKu+1rNB/0VyPiLUmKiJMR8V1EfC/pJUnrRlcmgKoGORpvSS9LOhIRzy9oX7HgaQ9KOlh/eQDqMsjR+DslPSLpgO39ZdszkjbbXiMpJB2T1H1uXgCNG+Ro/IeSFrsO9d76ywEwKvyCDkiCsANJEHYgCcIOJEHYgSQIO5AEYQeSIOxAEoQdSIKwA0kQdiAJwg4kQdiBJAg7kIQjYnwrszuSvljQtEzS6bEVcHkmtbZJrUuitmHVWdtPImLR67+NNeyXrNxuR0TRWAE9TGptk1qXRG3DGldtfIwHkiDsQBJNh32m4fX3Mqm1TWpdErUNayy1NfqdHcD4NL1nBzAmhB1IopGw215v+1+2P7P9dBM1dGP7mO0D5TTU7YZr2Wn7lO2DC9qW2n7P9tHyftE59hqqbSKm8e4xzXij267p6c/H/p3d9lWS/i3pV5KOS/pY0uaIODzWQrqwfUxSERGN/wDD9t2SvpH054j4Wdn2O0lnImJ7+Y9ySUT8ZkJqm5b0TdPTeJezFa1YOM24pAck/VoNbrsedW3SGLZbE3v2dZI+i4jPI+JbSa9L2thAHRMvIj6QdOai5o2SdpXLuzT/xzJ2XWqbCBExFxGflMtnJZ2fZrzRbdejrrFoIuwrJX254PFxTdZ87yHpXduztqeaLmYRyyNirlz+StLyJotZRN9pvMfpomnGJ2bbDTP9eVUcoLvUXRFxh6T7JT1WflydSDH/HWySxk4HmsZ7XBaZZvwHTW67Yac/r6qJsJ+QtGrB4xvLtokQESfK+1OS3tbkTUV98vwMuuX9qYbr+cEkTeO92DTjmoBt1+T0502E/WNJt9i+yfa1kh6WtKeBOi5h+7rywIlsXyfpPk3eVNR7JG0pl7dIeqfBWi4wKdN4d5tmXA1vu8anP4+Isd8kbdD8Efn/SPptEzV0qeunkv5Z3g41XZuk1zT/se6/mj+28aikH0vaJ+mopH9IWjpBtf1F0gFJn2o+WCsaqu0uzX9E/1TS/vK2oelt16OusWw3fi4LJMEBOiAJwg4kQdiBJAg7kARhB5Ig7EAShB1I4n/bsrfwFGCKDQAAAABJRU5ErkJggg==\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 배경 검은색(0)\n",
        "# 글씨 흰색(255)으로 변경하기\n",
        "# 0은 255로\n",
        "# 255은 0으로"
      ],
      "metadata": {
        "id": "ZQAIqvzH4gOf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "num = np.array(img)\n",
        "num"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_UVMsJB14gQx",
        "outputId": "4f3722c3-6bd6-430a-e9c8-2c9422b29b71"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[251, 251, 251, 251, 251, 251, 251, 251, 251, 251, 251, 251, 251,\n",
              "        251, 251, 251, 251, 251, 251, 251, 251, 251, 251, 251, 251, 251,\n",
              "        251, 251],\n",
              "       [251, 251, 251, 251, 251, 251, 251, 251, 251, 251, 251, 251, 251,\n",
              "        251, 251, 251, 251, 251, 251, 251, 251, 251, 251, 251, 251, 251,\n",
              "        251, 251],\n",
              "       [251, 251, 251, 251, 251, 251, 251, 251, 251, 251, 251, 251, 251,\n",
              "        251, 251, 153,  49, 153, 251, 251, 251, 251, 251, 251, 251, 251,\n",
              "        251, 251],\n",
              "       [251, 251, 251, 251, 251, 251, 251, 251, 251, 251, 251, 251, 251,\n",
              "        251, 153,   0,   0,   0, 251, 251, 251, 251, 251, 251, 251, 251,\n",
              "        251, 251],\n",
              "       [251, 251, 251, 251, 251, 251, 251, 251, 251, 251, 251, 251, 251,\n",
              "        153,   0,   0,   0,  49, 251, 251, 251, 251, 251, 251, 251, 251,\n",
              "        251, 251],\n",
              "       [251, 251, 251, 251, 251, 251, 251, 251, 251, 251, 251, 196,   6,\n",
              "          0,   0,   0,   0,   0, 251, 251, 251, 251, 251, 251, 251, 251,\n",
              "        251, 251],\n",
              "       [251, 251, 251, 251, 251, 251, 251, 251, 251, 251, 196,   0,   0,\n",
              "          0,   0,   0,   0,   0, 251, 251, 251, 251, 251, 251, 251, 251,\n",
              "        251, 251],\n",
              "       [251, 251, 251, 251, 251, 251, 251, 251, 251, 153,   0,   0,   0,\n",
              "          0,  98,   0,   0,   0, 251, 251, 251, 251, 251, 251, 251, 251,\n",
              "        251, 251],\n",
              "       [251, 251, 251, 251, 251, 251, 251, 159,  43,   0,   0,   0,   0,\n",
              "         98, 251,   0,   0,   0, 251, 251, 251, 251, 251, 251, 251, 251,\n",
              "        251, 251],\n",
              "       [251, 251, 251, 251, 251, 251, 196,   0,   0,   0,   0,   0, 104,\n",
              "        251, 251,   0,   0,   0, 251, 251, 251, 251, 251, 251, 251, 251,\n",
              "        251, 251],\n",
              "       [251, 251, 251, 251, 251, 202,   0,   0,   0,   0,  98, 251, 251,\n",
              "        251, 251,   0,   0,   0, 251, 251, 251, 251, 251, 251, 251, 251,\n",
              "        251, 251],\n",
              "       [251, 251, 251, 251, 251,   0,   0,   0,   0, 104, 251, 251, 251,\n",
              "        251, 251,   0,   0,   0, 251, 251, 251, 251, 251, 251, 251, 251,\n",
              "        251, 251],\n",
              "       [251, 251, 251, 251, 153,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  43, 153, 251,\n",
              "        251, 251],\n",
              "       [251, 251, 251, 251,  43,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 251,\n",
              "        251, 251],\n",
              "       [251, 251, 251, 251, 104,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  98, 251,\n",
              "        251, 251],\n",
              "       [251, 251, 251, 251, 251, 251, 251, 251, 251, 251, 251, 251, 251,\n",
              "        251, 251,   0,   0,   0, 251, 251, 251, 251, 251, 251, 251, 251,\n",
              "        251, 251],\n",
              "       [251, 251, 251, 251, 251, 251, 251, 251, 251, 251, 251, 251, 251,\n",
              "        251, 251,   0,   0,   0, 251, 251, 251, 251, 251, 251, 251, 251,\n",
              "        251, 251],\n",
              "       [251, 251, 251, 251, 251, 251, 251, 251, 251, 251, 251, 251, 251,\n",
              "        251, 251,   0,   0,   0, 251, 251, 251, 251, 251, 251, 251, 251,\n",
              "        251, 251],\n",
              "       [251, 251, 251, 251, 251, 251, 251, 251, 251, 251, 251, 251, 251,\n",
              "        251, 251,   0,   0,   0, 251, 251, 251, 251, 251, 251, 251, 251,\n",
              "        251, 251],\n",
              "       [251, 251, 251, 251, 251, 251, 251, 251, 251, 251, 251, 251, 251,\n",
              "        251, 251,   0,   0,   0, 251, 251, 251, 251, 251, 251, 251, 251,\n",
              "        251, 251],\n",
              "       [251, 251, 251, 251, 251, 251, 251, 251, 251, 251, 251, 251, 251,\n",
              "        251, 251,   0,   0,   0, 251, 251, 251, 251, 251, 251, 251, 251,\n",
              "        251, 251],\n",
              "       [251, 251, 251, 251, 251, 251, 251, 251, 251, 251, 251, 251, 251,\n",
              "        251, 251,   0,   0,   0, 251, 251, 251, 251, 251, 251, 251, 251,\n",
              "        251, 251],\n",
              "       [251, 251, 251, 251, 251, 251, 251, 251, 251, 251, 251, 251, 251,\n",
              "        251, 251, 147,   0,  98, 251, 251, 251, 251, 251, 251, 251, 251,\n",
              "        251, 251],\n",
              "       [251, 251, 251, 251, 251, 251, 251, 251, 251, 251, 251, 251, 251,\n",
              "        251, 251, 251, 251, 251, 251, 251, 251, 251, 251, 251, 251, 251,\n",
              "        251, 251],\n",
              "       [251, 251, 251, 251, 251, 251, 251, 251, 251, 251, 251, 251, 251,\n",
              "        251, 251, 251, 251, 251, 251, 251, 251, 251, 251, 251, 251, 251,\n",
              "        251, 251],\n",
              "       [251, 251, 251, 251, 251, 251, 251, 251, 251, 251, 251, 251, 251,\n",
              "        251, 251, 251, 251, 251, 251, 251, 251, 251, 251, 251, 251, 251,\n",
              "        251, 251],\n",
              "       [251, 251, 251, 251, 251, 251, 251, 251, 251, 251, 251, 251, 251,\n",
              "        251, 251, 251, 251, 251, 251, 251, 251, 251, 251, 251, 251, 251,\n",
              "        251, 251],\n",
              "       [251, 251, 251, 251, 251, 251, 251, 251, 251, 251, 251, 251, 251,\n",
              "        251, 251, 251, 251, 251, 251, 251, 251, 251, 251, 251, 251, 251,\n",
              "        251, 251]], dtype=uint8)"
            ]
          },
          "metadata": {},
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 픽셀값 변환\n",
        "num = 255 -num"
      ],
      "metadata": {
        "id": "LC0_SO714gS8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zReS2AIw4gVP",
        "outputId": "ea7f8d1a-0e5a-4ac9-98e6-3436b63286ef"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(28, 28)"
            ]
          },
          "metadata": {},
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 차원 수정\n",
        "num = num.reshape(1, 784)"
      ],
      "metadata": {
        "id": "xm6t8OIb4gXm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 값 변경\n",
        "num = num.astype('float') / 255"
      ],
      "metadata": {
        "id": "tOo0oGut4gZu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model4.predict(num).argmax()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9BB0y6dO4gcQ",
        "outputId": "08e15f46-e4f1-4196-ec51-cfa9a5d8c0be"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 23ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "9"
            ]
          },
          "metadata": {},
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Dense를 사용한 MLP모델은 이미지 학습이 안된다"
      ],
      "metadata": {
        "id": "I2lQhv_e4geh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 모델 저장/ 모델 불러오기\n",
        "# h5, hdf5 : 딥러닝 모델의 확장자\n",
        "model4.save('./content/hand_model.h5')"
      ],
      "metadata": {
        "id": "CkVYw-DD3Q-c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 모델 불러오기\n",
        "from tensorflow.keras.models import load_model\n",
        "model5 = load_model('/content/content/hand_model.h5')"
      ],
      "metadata": {
        "id": "3hxyug8K_hYr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model5.predict(num).argmax()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xSqPR0D2_hbt",
        "outputId": "d307bc26-facf-404b-e621-7446d8a9dde9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 69ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "9"
            ]
          },
          "metadata": {},
          "execution_count": 80
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 중간 모델 저장(ModelCheckPoint) -> 좋았던 모델 저장\n",
        "# 학습 중단(EarlyStopping) : 결과가 나빠지면 학습 중단\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping"
      ],
      "metadata": {
        "id": "bb2zH0fi_heN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 모델 정장 경로 / 파일 이름 설정\n",
        "# epch:03d : epochs를 3자리 정수로 표현\n",
        "# val_accuracy:.4f : 모델의 검증 정확도를 소수점 4번째 자리까지포현하겠다\n",
        "# ex) handmodel-013-0.9753.hdf5\n",
        "modelpath = '/content/handmodel-{epoch:03d}-{val_accuracy:.4f}.hdf5'"
      ],
      "metadata": {
        "id": "6DvXcUEW_hge"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ModelCheckpoint : 전보다 나아지면 저장\n",
        "mcp = ModelCheckpoint(\n",
        "    \n",
        "    filepath = modelpath, # 저장될 경로\n",
        "    monitor = 'val_accuracy',# 검증 정확도를 기준으로 나아진걸 판단\n",
        "    save_best_only = True, # 개선된 결과만 저장\n",
        "    verbose = 1 # 과정 출력 여부 0 -> 출력안함, 1-> 일부만 출력, 2-> 거의다 출력, 3-> 전부 출력\n",
        "\n",
        ")\n"
      ],
      "metadata": {
        "id": "A5M4xPA3_hiz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# EarlyStopping : 전보다 개선되지 않으면 학습 중단\n",
        "es = EarlyStopping(\n",
        "    monitor = 'val_accuracy',\n",
        "    patience = 5 # 전보다 개선되지 않더라도 기다릴 횟수\n",
        "\n",
        ")"
      ],
      "metadata": {
        "id": "vbW7ie_M_hlG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras import Sequential # 딥러닝 모델의 뼈대\n",
        "from tensorflow.keras.layers import InputLayer, Dense\n",
        "\n",
        "model6 = Sequential()\n",
        "\n",
        "model6.add(Dense(units = 512, activation = 'relu', input_dim=784)) \n",
        "\n",
        "# 학습방법 설정\n",
        "model6.add(Dense(units = 34, activation = 'relu')) \n",
        "model6.add(Dense(units = 54, activation = 'relu')) \n",
        "model6.add(Dense(units = 26, activation = 'relu')) \n",
        "\n",
        "model6.add(Dense(units = 10, activation = 'softmax')) \n",
        "\n",
        "model6.compile(loss ='categorical_crossentropy', \n",
        "               optimizer ='Adam', \n",
        "               metrics=['accuracy'])\n",
        "model6.fit(X_train,y_train, epochs = 100, validation_data = (X_test,y_test),\n",
        "           callbacks = [mcp,es])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o13HKVaB_hns",
        "outputId": "8ef36ad1-7d36-4d1c-b75f-fa230ed5780f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "1868/1875 [============================>.] - ETA: 0s - loss: 0.2412 - accuracy: 0.9268\n",
            "Epoch 1: val_accuracy did not improve from 0.98520\n",
            "1875/1875 [==============================] - 10s 4ms/step - loss: 0.2407 - accuracy: 0.9269 - val_loss: 0.1065 - val_accuracy: 0.9667\n",
            "Epoch 2/100\n",
            "1874/1875 [============================>.] - ETA: 0s - loss: 0.0986 - accuracy: 0.9701\n",
            "Epoch 2: val_accuracy did not improve from 0.98520\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0985 - accuracy: 0.9701 - val_loss: 0.0858 - val_accuracy: 0.9736\n",
            "Epoch 3/100\n",
            "1868/1875 [============================>.] - ETA: 0s - loss: 0.0659 - accuracy: 0.9796\n",
            "Epoch 3: val_accuracy did not improve from 0.98520\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0658 - accuracy: 0.9796 - val_loss: 0.0865 - val_accuracy: 0.9739\n",
            "Epoch 4/100\n",
            "1872/1875 [============================>.] - ETA: 0s - loss: 0.0506 - accuracy: 0.9844\n",
            "Epoch 4: val_accuracy did not improve from 0.98520\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0505 - accuracy: 0.9844 - val_loss: 0.0756 - val_accuracy: 0.9782\n",
            "Epoch 5/100\n",
            "1869/1875 [============================>.] - ETA: 0s - loss: 0.0419 - accuracy: 0.9870\n",
            "Epoch 5: val_accuracy did not improve from 0.98520\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: 0.0420 - accuracy: 0.9870 - val_loss: 0.0746 - val_accuracy: 0.9793\n",
            "Epoch 6/100\n",
            "1873/1875 [============================>.] - ETA: 0s - loss: 0.0331 - accuracy: 0.9894\n",
            "Epoch 6: val_accuracy did not improve from 0.98520\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0331 - accuracy: 0.9894 - val_loss: 0.0880 - val_accuracy: 0.9762\n",
            "Epoch 7/100\n",
            "1862/1875 [============================>.] - ETA: 0s - loss: 0.0285 - accuracy: 0.9911\n",
            "Epoch 7: val_accuracy did not improve from 0.98520\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: 0.0285 - accuracy: 0.9911 - val_loss: 0.0924 - val_accuracy: 0.9771\n",
            "Epoch 8/100\n",
            "1873/1875 [============================>.] - ETA: 0s - loss: 0.0249 - accuracy: 0.9921\n",
            "Epoch 8: val_accuracy did not improve from 0.98520\n",
            "1875/1875 [==============================] - 12s 6ms/step - loss: 0.0249 - accuracy: 0.9921 - val_loss: 0.0878 - val_accuracy: 0.9770\n",
            "Epoch 9/100\n",
            "1868/1875 [============================>.] - ETA: 0s - loss: 0.0233 - accuracy: 0.9925\n",
            "Epoch 9: val_accuracy did not improve from 0.98520\n",
            "1875/1875 [==============================] - 10s 5ms/step - loss: 0.0233 - accuracy: 0.9925 - val_loss: 0.0760 - val_accuracy: 0.9802\n",
            "Epoch 10/100\n",
            "1874/1875 [============================>.] - ETA: 0s - loss: 0.0200 - accuracy: 0.9938\n",
            "Epoch 10: val_accuracy did not improve from 0.98520\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0200 - accuracy: 0.9938 - val_loss: 0.0905 - val_accuracy: 0.9789\n",
            "Epoch 11/100\n",
            "1866/1875 [============================>.] - ETA: 0s - loss: 0.0187 - accuracy: 0.9940\n",
            "Epoch 11: val_accuracy did not improve from 0.98520\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: 0.0186 - accuracy: 0.9940 - val_loss: 0.0910 - val_accuracy: 0.9781\n",
            "Epoch 12/100\n",
            "1872/1875 [============================>.] - ETA: 0s - loss: 0.0175 - accuracy: 0.9946\n",
            "Epoch 12: val_accuracy did not improve from 0.98520\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0175 - accuracy: 0.9946 - val_loss: 0.0823 - val_accuracy: 0.9817\n",
            "Epoch 13/100\n",
            "1868/1875 [============================>.] - ETA: 0s - loss: 0.0147 - accuracy: 0.9952\n",
            "Epoch 13: val_accuracy did not improve from 0.98520\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0149 - accuracy: 0.9951 - val_loss: 0.0865 - val_accuracy: 0.9800\n",
            "Epoch 14/100\n",
            "1862/1875 [============================>.] - ETA: 0s - loss: 0.0161 - accuracy: 0.9949\n",
            "Epoch 14: val_accuracy did not improve from 0.98520\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0161 - accuracy: 0.9948 - val_loss: 0.0899 - val_accuracy: 0.9797\n",
            "Epoch 15/100\n",
            "1872/1875 [============================>.] - ETA: 0s - loss: 0.0134 - accuracy: 0.9956\n",
            "Epoch 15: val_accuracy did not improve from 0.98520\n",
            "1875/1875 [==============================] - 10s 5ms/step - loss: 0.0134 - accuracy: 0.9956 - val_loss: 0.0977 - val_accuracy: 0.9804\n",
            "Epoch 16/100\n",
            "1863/1875 [============================>.] - ETA: 0s - loss: 0.0126 - accuracy: 0.9961\n",
            "Epoch 16: val_accuracy did not improve from 0.98520\n",
            "1875/1875 [==============================] - 10s 5ms/step - loss: 0.0125 - accuracy: 0.9961 - val_loss: 0.0931 - val_accuracy: 0.9807\n",
            "Epoch 17/100\n",
            "1874/1875 [============================>.] - ETA: 0s - loss: 0.0131 - accuracy: 0.9961\n",
            "Epoch 17: val_accuracy did not improve from 0.98520\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: 0.0131 - accuracy: 0.9961 - val_loss: 0.0901 - val_accuracy: 0.9822\n",
            "Epoch 18/100\n",
            "1864/1875 [============================>.] - ETA: 0s - loss: 0.0102 - accuracy: 0.9969\n",
            "Epoch 18: val_accuracy did not improve from 0.98520\n",
            "1875/1875 [==============================] - 10s 5ms/step - loss: 0.0102 - accuracy: 0.9969 - val_loss: 0.1025 - val_accuracy: 0.9791\n",
            "Epoch 19/100\n",
            "1872/1875 [============================>.] - ETA: 0s - loss: 0.0114 - accuracy: 0.9967\n",
            "Epoch 19: val_accuracy did not improve from 0.98520\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: 0.0114 - accuracy: 0.9967 - val_loss: 0.0854 - val_accuracy: 0.9829\n",
            "Epoch 20/100\n",
            "1873/1875 [============================>.] - ETA: 0s - loss: 0.0111 - accuracy: 0.9967\n",
            "Epoch 20: val_accuracy did not improve from 0.98520\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0111 - accuracy: 0.9967 - val_loss: 0.0968 - val_accuracy: 0.9790\n",
            "Epoch 21/100\n",
            "1873/1875 [============================>.] - ETA: 0s - loss: 0.0096 - accuracy: 0.9973\n",
            "Epoch 21: val_accuracy did not improve from 0.98520\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0096 - accuracy: 0.9973 - val_loss: 0.1100 - val_accuracy: 0.9791\n",
            "Epoch 22/100\n",
            "1868/1875 [============================>.] - ETA: 0s - loss: 0.0097 - accuracy: 0.9974\n",
            "Epoch 22: val_accuracy did not improve from 0.98520\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0097 - accuracy: 0.9974 - val_loss: 0.1000 - val_accuracy: 0.9825\n",
            "Epoch 23/100\n",
            "1875/1875 [==============================] - ETA: 0s - loss: 0.0083 - accuracy: 0.9975\n",
            "Epoch 23: val_accuracy did not improve from 0.98520\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0083 - accuracy: 0.9975 - val_loss: 0.1381 - val_accuracy: 0.9754\n",
            "Epoch 24/100\n",
            "1875/1875 [==============================] - ETA: 0s - loss: 0.0082 - accuracy: 0.9977\n",
            "Epoch 24: val_accuracy did not improve from 0.98520\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0082 - accuracy: 0.9977 - val_loss: 0.1052 - val_accuracy: 0.9822\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f6f96bb43d0>"
            ]
          },
          "metadata": {},
          "execution_count": 93
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# MLP\n",
        "# Dense층을 사용 - 1차원만 학습 가능-> csv,table 형식의 데이터만 학습 가능"
      ],
      "metadata": {
        "id": "g5ekGPev_hpt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# CNN\n",
        "# Convolution, Pooling, Dense층을 사용 - 다차원의 데이터 학습 가능 -> 이미지가 학습 가능\n",
        " "
      ],
      "metadata": {
        "id": "IzTKPv9qSrge"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "E1L7wRpaSrjT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "6fmgRoMZSrmC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "va-Jt1aNSrpZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "JJEt5bSYSrsF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "tYmBbGWmSrwp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ZiVEtpQsSrzp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "H_SWbOdZSr38"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "xmWFv0IrSr6J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "zj3IacnO_hsF"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}